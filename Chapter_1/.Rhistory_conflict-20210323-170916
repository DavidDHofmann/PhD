celebrities = data.frame(name = c("Andrew", "Mathew", "Dany", "Philip", "John", "Bing", "Monica"),
age = c(28, 23, 49, 29, 38, 23, 29),
income = c(25.2, 10.5, 11, 21.9, 44, 11.5, 45))
# R function
f = function(x, output) {
# x is the row of type Character
# access element in first column
name = x[1]
# access element in second column
income = x[3]
#your code to process x
cat(name, income, "\n")
}
#apply(X, MARGIN, FUN, â€¦)
apply(celebrities, 1, f)
library(taxize)
get_wiki("Lycaon pictus")
get_ids("Lycaon pictus")
get_colid("Lycaon pictus")
get_pow("Lycaon pictus")
get_natservid("Lycaon pictus")
id <- get_natservid("Lycaon pictus")
id
classification(id)
classification(id, db = "natserv")
classification("Lycaon pictus")
classification("Lycaon pictus", db = "natserv")
classification("Canis lupus", db = "natserv")
classification("Canis lupus lupus", db = "itis")
classification("Canis lupus", db = "natserv")
classification('Gadus morhua', db = 'worms')
classification("Canis lupus", db = 'worms')
classification("Canis lupus", db = 'ncbi')
classification("Lycaon pictus", db = 'ncbi')
classification("Canis lupus", db = 'ncbi')
classification(get_wiki("Lycaon pictus", "species"))
classification("Canis lupus", db = "pow")
classification("Canis lupus", db = "natserv")
get_gbifid(c("Canis lupus"))
get_gbifid(c("Lycaon pictus"))
get_gbifid(c("Canis lupus", "Lycaon pictus"))
id <- get_gbifid(c("Canis lupus", "Lycaon pictus"))
classification(id, db = "gbif")
library(tidyverse)
if(!require(gapminder)) install.packages("gapminder")
data(gapminder, package = "gapminder")
df <- gapminder %>%
filter(continent == "Europe", year == 2007)
p <- df %>%
ggplot(aes(gdpPercap, lifeExp)) +
geom_point() +
labs(
x = "GDP per capita",
y = "Life Expextancy (years)",
title = "Average Life Expectancy in European countries, 2007",
subtitle = "source: Gapminder data"
) +
theme_classic()
p
library(lemon)
p + lemon::coord_capped_cart(bottom = 'both', left = 'both')
knitr::opts_chunk$set(echo = TRUE)
x1 <- rnorm(n = 1e5, mean = 5, sd = 10)
hist(x1)
hist(x1)
#
hist(NA)
#
hist(0)
#
hist(0)
#
hist(0)
# Simulate some data without interactions
n <- 1e5
x1 <- rnorm(n, mean = 5, sd = 2)
x2 <- rnorm(n, mean = -2, sd = 0.2)
e <- rnorm(n, mean = 0, sd = 1)
y <- 1 + 2 * x1 + 3 * x2 + e
dat <- data.frame(y, x1, x2)
dat
dat <- data.frame(y, x1, x2)
dat <- data.frame(y, x1, x2)
dat
# Run a model without scaling for reference
mod1 <- lm(y ~ x1 + x2, data = dat)
summary(mod1)
coefs1 <- coef(mod1)
coefs1
# Run a model with scaling and extract model coefficients
mod2 <- lm(y ~ scale(x1) + scale(x2), data = dat)
coefs2 <- coef(mod2)
# Try to backtransform the coefficients from the scaled model
coefs2[1]
# Try to backtransform the coefficients from the scaled model
coefs2[1] - coefs[2] * mean(x1) / sd(x1) - coefs[3] * mean(x2) / sd(x2)
# Try to backtransform the coefficients from the scaled model
coefs2[1] - coefs2[2] * mean(x1) / sd(x1) - coefs2[3] * mean(x2) / sd(x2)
coefs1
coefs1[2]
coefs2[2] / sd(x1)
# Try to backtransform the coefficients from the scaled model
coefs1[1]
coefs2[1] - coefs2[2] * mean(x1) / sd(x1) - coefs2[3] * mean(x2) / sd(x2)
coefs1[2]
coefs2[2] / sd(x1)
coefs1[3]
coefs2[3] / sd(x2)
# Simulate some data with an interaction
n <- 1e5
x1 <- rnorm(n, mean = 5, sd = 2)
x2 <- rnorm(n, mean = -2, sd = 0.2)
e <- rnorm(n, mean = 0, sd = 1)
n <- 1e5
x1 <- rnorm(n, mean = 5, sd = 2)
x2 <- rnorm(n, mean = -2, sd = 0.2)
e <- rnorm(n, mean = 0, sd = 1)
y <- 1 + 2 * x1 + 3 * x2 + 0.5 * x1 * x2 + e
dat <- data.frame(y, x1, x2)
# Run a model without scaling and extract the model coefficients
mod1 <- lm(y ~ x1 + x2 + x1:x2, data = dat)
coefs1 <- coef(mod1)
coefs1
# Run a model with scaling and extract model coefficients
mod2 <- lm(y ~ scale(x1) + scale(x2) + scale(x1:x2), data = dat)
# Run a model with scaling and extract model coefficients
mod2 <- lm(y ~ scale(x1) + scale(x2) + scale(x1 * x2), data = dat)
coefs2 <- coef(mod2)
coefs2
# Try to backtransform the coefficients from the scaled model
coefs1[1]
coefs2[1] - coefs2[2] * mean(x1) / sd(x1) - coefs2[3] * mean(x2) / sd(x2) -
coefs2[4] * mean(x1 * x2) / sd(x1 * x2)
coefs1[2]
coefs2[2] / sd(x1)
coefs1[3]
coefs2[3] / sd(x2)
# Simulate some data with an interaction
n <- 1e5
x1 <- rnorm(n, mean = 5, sd = 2)
x2 <- rnorm(n, mean = -2, sd = 0.2)
e <- rnorm(n, mean = 0, sd = 1)
y <- 1 + 2 * x1 + 3 * x2 + 0.5 * x1 * x2 + e
dat <- data.frame(y, x1, x2)
# Run a model without scaling and extract the model coefficients
mod1 <- lm(y ~ x1 + x2 + x1:x2, data = dat)
coefs1 <- coef(mod1)
# Run a model with scaling and extract model coefficients
mod2 <- lm(y ~ scale(x1) + scale(x2) + scale(x1):scale(x2), data = dat)
coefs2 <- coef(mod2)
# Try to backtransform the coefficients from the scaled model
coefs1[1]
coefs2[1] - coefs2[2] * mean(x1) / sd(x1) - coefs2[3] * mean(x2) / sd(x2) -
coefs2[4] * (mean(x1) * mean(x2)) / (sd(x1) * sd(x2))
coefs2[1] + coefs2[2] * mean(x1) / sd(x1) + coefs2[3] * mean(x2) / sd(x2) -
coefs2[4] * (mean(x1) * mean(x2)) / (sd(x1) * sd(x2))
coefs2[1]
coefs2[1] + coefs2[2] * mean(x1) / sd(x1) coefs2[3] * mean(x2) / sd(x2) -
coefs2[4] * (mean(x1) * mean(x2)) / (sd(x1) * sd(x2))
coefs2[1] + coefs2[2] * mean(x1) / sd(x1) coefs2[3] * mean(x2) / sd(x2) -
coefs2[4] * (mean(x1) * mean(x2)) / (sd(x1) * sd(x2))
coefs2[1] + coefs2[2] * mean(x1) / sd(x1) coefs2[3] * mean(x2) / sd(x2) -
coefs2[4] * (mean(x1) * mean(x2)) / (sd(x1) * sd(x2))
coefs2[4] * (mean(x1) * mean(x2)) / (sd(x1) * sd(x2))
coefs2[1] - coefs2[2] * mean(x1) / sd(x1) - coefs2[3] * mean(x2) / sd(x2) -
coefs2[4] * (mean(x1) * mean(x2)) / (sd(x1) * sd(x2))
coefs1[2]
coefs2[2] / sd(x1)
coefs2[2] / sd(x1) - coefs[4] * mean(x2) / sd(x1) * sd(x2)
coefs2[2] / sd(x1) - coefs2[4] * mean(x2) / sd(x1) * sd(x2)
coefs1[2]
# Run a model with scaling and extract model coefficients
mod2 <- lm(y ~ scale(x1) + scale(x2) + scale(x1):scale(x2), data = dat)
coefs2 <- coef(mod2)
# Try to backtransform the coefficients from the scaled model
coefs1[1]
coefs2[1] - coefs2[2] * mean(x1) / sd(x1) - coefs2[3] * mean(x2) / sd(x2) -
coefs2[4] * (mean(x1) * mean(x2)) / (sd(x1) * sd(x2))
coefs1[2]
coefs2[2] / sd(x1) - coefs2[4] * mean(x2) / sd(x1) * sd(x2)
coefs2[2] / sd(x1) - coefs2[4] * mean(x2) / (sd(x1) * sd(x2))
coefs2[3] / sd(x2) - coefs2[4] * mean(x1) / (sd(x1) * sd(x2))
coefs1[3]
coefs2[1] - coefs2[2] * mean(x1) / sd(x1) - coefs2[3] * mean(x2) / sd(x2) -
(coefs2[4] * (mean(x1) * mean(x2))) / (sd(x1) * sd(x2))
coefs2[1] - coefs2[2] * mean(x1) / sd(x1) - coefs2[3] * mean(x2) / sd(x2) -
coefs2[4] * mean(x1) * mean(x2) / (sd(x1) * sd(x2))
coefs2
# Simulate some data with an interaction
n <- 1e5
x1 <- rnorm(n, mean = 5, sd = 2)
x2 <- rnorm(n, mean = -2, sd = 0.2)
e <- rnorm(n, mean = 0, sd = 1)
y <- 1 + 2 * x1 + 3 * x2 + 0.5 * x1 * x2 + e
dat <- data.frame(y, x1, x2)
# Run a model without scaling and extract the model coefficients
mod1 <- lm(y ~ x1 + x2 + x1:x2, data = dat)
coefs1 <- coef(mod1)
# Run a model with scaling and extract model coefficients
mod2 <- lm(y ~ scale(x1) + scale(x2) + scale(x1):scale(x2), data = dat)
coefs2 <- coef(mod2)
# Try to backtransform the coefficients from the scaled model
coefs1[1]
coefs2[1] - coefs2[2] * mean(x1) / sd(x1) - coefs2[3] * mean(x2) / sd(x2) -
coefs2[4] * mean(x1) * mean(x2) / (sd(x1) * sd(x2))
coefs2
coefs1[4]
coefs2[4] / (sd(x1) * sd(x2))
n <- 1e5
x1 <- rnorm(n, mean = 5, sd = 2)
x2 <- rnorm(n, mean = -2, sd = 0.2)
e <- rnorm(n, mean = 0, sd = 1)
y <- 1 + 2 * x1 + 3 * x2 + 0.5 * x1 * x2 + e
dat <- data.frame(y, x1, x2)
# Run a model without scaling and extract the model coefficients
mod1 <- lm(y ~ x1 + x2 + x1:x2, data = dat)
coefs1 <- coef(mod1)
# Run a model with scaling and extract model coefficients
mod2 <- lm(y ~ scale(x1) + scale(x2) + scale(x1 * x2), data = dat)
coefs2 <- coef(mod2)
# Try to backtransform the coefficients from the scaled model
coefs1[1]
coefs2[1] - coefs2[2] * mean(x1) / sd(x1) - coefs2[3] * mean(x2) / sd(x2) -
coefs2[4] * mean(x1 * x2) / sd(x1 * x2)
coefs1[2]
coefs2[2] / sd(x1)
coefs1[3]
coefs2[3] / sd(x2)
coefs1[4]
coefs2[4] / (sd(x1 * x2))
# Try to backtransform the coefficients from the scaled model
# Intercept
coefs1[1]
coefs2[1] - coefs2[2] * mean(x1) / sd(x1) - coefs2[3] * mean(x2) / sd(x2) -
coefs2[4] * mean(x1) * mean(x2) / (sd(x1) * sd(x2))
coefs2[1] - coefs2[2] * mean(x1) / sd(x1) - coefs2[3] * mean(x2) / sd(x2) -
(coefs2[4] * mean(x1) * mean(x2)) / (sd(x1) * sd(x2))
coefs2[1] - coefs2[2] * mean(x1) / sd(x1) - coefs2[3] * mean(x2) / sd(x2) +
coefs2[4] * mean(x1) * mean(x2) / (sd(x1) * sd(x2))
# Try to backtransform the coefficients from the scaled model
# Intercept
coefs1[1]
n <- 1e5
x1 <- rnorm(n, mean = 5, sd = 2)
x2 <- rnorm(n, mean = -2, sd = 0.2)
e <- rnorm(n, mean = 0, sd = 1)
y <- 1 + 2 * x1 + 3 * x2 + 0.5 * x1 * x2 + e
dat <- data.frame(y, x1, x2)
# Run a model without scaling and extract the model coefficients
mod1 <- lm(y ~ x1 + x2 + x1:x2, data = dat)
coefs1 <- coef(mod1)
# Run a model with scaling and extract model coefficients
mod2 <- lm(y ~ scale(x1) + scale(x2) + scale(x1):scale(x2), data = dat)
coefs2 <- coef(mod2)
# Try to backtransform the coefficients from the scaled model
# Intercept
coefs1[1]
coefs2[1] - coefs2[2] * mean(x1) / sd(x1) - coefs2[3] * mean(x2) / sd(x2) +
coefs2[4] * mean(x1) * mean(x2) / (sd(x1) * sd(x2))
# Simulate covariate
set.seed(1234)
x1 <- rnorm(n = 1e5, mean = 20, sd = 3)
# Scale it
x1_scaled <- scale(x1)
# Compare the histograms of the two values
p1 <- hist(x1, plot = F)
p2 <- hist(x1_scaled, plot = F)
plot(p1, col = adjustcolor("blue", alpha.f = 0.5), xlim = c(-5, 30), main = NA)
plot(p2, col = adjustcolor("darkgreen", alpha.f = 0.5), xlim = c(0 , 10), add = T)
text(20, 25400, "unscaled")
# Simulate two covariates
x1 <- rnorm(10000, 5, 2)
x2 <- rnorm(10000, 15, 2)
plot(x1 * x2)
# Simulate two covariates
x1 <- rnorm(10000, 5, 2)
x2 <- rnorm(10000, 15, 2)
# Scale all of the variables
x1_scaled <- scale(x1)
x2_scaled <- scale(x2)
x1x2_scaled <- scale(x1 * x2)
# Check for correlation with interaction term
as.vector(cor(x1, x1 * x2))
as.vector(cor(x1_scaled, x1x2_scaled))
# Simulate two covariates
x1 <- rnorm(10000, 5, 2)
x2 <- rnorm(10000, 15, 2)
# Check for correlation with interaction term
cor(x1, x1 * x2)
cor(x1, scale(x1) * scale(x2))
cor(scale(x1), scale(x1) * scale(x2))
cor(scale(x1), scale(x1 * x2))
library(Rcpp)
Rcpp.package.skeleton()
getwd()
library(pbapply)
x <- list(a = 1:10, beta = exp(-3:3), logic = c(TRUE,FALSE,FALSE,TRUE))
# compute the list mean for each list element
pblapply(x,mean)
# median and quartiles for each list element
pblapply(x, quantile, probs = 1:3/4)
pbsapply(x, quantile)
i39 <- pbsapply(3:9, seq) # list of vectors
pbsapply(i39, fivenum)
################################################################################
#### Rasterization of Simulated Dispersal Trajectories
################################################################################
# Description: In this script, we rasterize the simulated dispersal
# trajectories. To achieve this, we'll first rasterize trajectories by their
# source points. Afterwards, we can combine them them into a single "heatmap".
# Clear R's brain
rm(list = ls())
# Change the working directory
wd <- "/home/david/ownCloud/University/15. PhD/Chapter_1"
setwd(wd)
# Load required packages
library(terra)            # For quick raster manipulation
library(raster)           # For general raster manipulation
library(tidyverse)        # For data wrangling
library(rgeos)            # For manipulating vector data
library(lubridate)        # For working with dates
library(viridis)          # For nicer colors
library(tictoc)           # To keep track of processing time
library(pbmcapply)        # To show progress bar in mclapply calls
library(tmap)             # For nice spatial plots
library(davidoff)         # Custom functions
################################################################################
#### Required Functions
################################################################################
# Function to convert simulation to track
sim2tracks <- function(simulation = NULL, keep.data = F){
# # Unless keep.data is desired, remove all unnecessary columns
# if (!keep.data){
#   simulation <- simulation[, c("x", "y")]
# }
# # Calculate number of steps
# steps <- nrow(simulation) - 1
# If data does not need to be kept
# if (!keep.data){
coordinates(simulation) <- c("x", "y")
lines <- spLines(simulation)
crs(lines) <- CRS("+init=epsg:4326")
return(lines)
# # If data needs to be kept
# } else {
#   pts <- simulation
#   coordinates(pts) <- c("x", "y")
#   line <- spLines(pts)
#   lines <- createSegments(line)
#   lines <- as(lines, "SpatialLinesDataFrame")
#   lines@data <- simulation[1:steps, ]
#   crs(lines) <- CRS("+init=epsg:4326")
#   return(lines)
# }
}
# Function to convert multiple simulations to multiple tracks
sims2tracks <- function(
simulations = NULL
, id          = "TrackID"
# , keep.data   = F
, mc.cores    = 1
){
# # Copy relevant data
# if (!keep.data){
#   simulations <- simulations[, c("x", "y", "TrackID")]
# }
# Nest data by id
simulations <- nest(simulations, data = -all_of(id))
# Coerce each trajectory to a spatial lines object
lines <- pbmclapply(1:nrow(simulations)
, mc.cores           = mc.cores
, ignore.interactive = T
, FUN                = function(x){
l <- sim2tracks(
simulation = simulations$data[[x]]
# , keep.data  = keep.data
)
l$TrackID <- simulations$TrackID[x]
return(l)
})
# Bind them
lines <- do.call(rbind, lines)
# Return the lines
return(lines)
}
# Function to rasterize trajectories of a desired source point after a desired
# amount of time (i.e. after a desired number of steps)
rasterizeSims <- function(
simulations = NULL      # Simulated trajectories
, steps       = 400       # How many steps should be considered
, areas       = "Main"    # Simulations from which areas?
){
# Subset to corresponding data
simulations <- simulations[which(
simulations$StepNumber <= steps &
simulations$Area %in% areas
),
]
# Create tracks that fulfill the above requirements
cat("Creating spatial lines...\n")
sub_traj <- sims2tracks(
simulations = simulations
, id          = "TrackID"
, mc.cores    = 1
)
# Remove data and create spatial lines
sub_traj <- as(sub_traj, "SpatialLines")
crs(sub_traj) <- CRS("+init=epsg:4326")
# Coerce lines to "vect" and crop raster
sub_traj <- vect(sub_traj)
# r_crop <- crop(r, ext(sub_traj))
r_crop <- r
# Rasterize lines onto the cropped raster
cat("Rasterizing spatial lines...\n")
heatmap <- rasterizeTerra(sub_traj, r_crop)
# Clean garbage
gc()
# Return the resulting heatmap
return(heatmap)
}
################################################################################
#### Load and Prepare Data
################################################################################
# Load the reference raster
r <- rast("03_Data/02_CleanData/00_General_Raster.tif")
# For this part we can reduce the resolution of the raster drastically
r <- aggregate(r, fact = 10)
# Load the simulated dispersal trajectories
# sims <- read_rds("03_Data/03_Results/99_DispersalSimulation.rds")
sims <- read_rds("03_Data/03_Results/99_DispersalSimulationSub.rds")
sims <- subsims(sims, nid = 100)
sims <- ungroup(sims)
# Remove undesired columns
sims <- sims[, c("x", "y", "TrackID", "StepNumber", "Area")]
# Collect garbage
gc()
# Check out the number of rows
nrow(sims) / 1e6
################################################################################
#### Rasterize Trajectories
################################################################################
# Create a dataframe with all source points and points in time at which we want
# to rasterize trajectories
rasterized <- as_tibble(
expand.grid(
steps            = c(68, 125, 250, 500, 1000, 2000)
, area             = unique(sims$Area)
, stringsAsFactors = F
)
)
# Add a column for temporary but unique filename. Make sure the tempdir has
# plenty of storage.
rasterized$filename <- tempfile(
pattern = paste0(
"steps_", rasterized$steps
, "_area_", rasterized$area
, "_"
)
, fileext = ".tif"
)
# Rasterize simulated trajectories
heatmaps <- pbmclapply(1:nrow(rasterized)
, ignore.interactive = T
, mc.cores           = detectCores() - 1
, FUN                = function(i){
# Rasterize trajectories
heatmap <- rasterizeSims(
simulations = sims
, steps       = rasterized$steps[i]
, area        = rasterized$area[i]
)
# Make sure the map is not stored in memory but on disk
heatmap <- terra::writeRaster(heatmap, rasterized$filename[i], overwrite = T)
# Print update and clean garbage
cat(i, " out of ", nrow(rasterized), " done...\n")
gc()
# Return the final raster
return(heatmap)
})
# For whatever reason the final list does not correctly link to the rasters and
# we need to reload the rasters using their temporary filenames
heatmaps <- lapply(1:nrow(rasterized), function(x){
rast(rasterized$filename[x])
})
# Prepare nice layernames
names <- paste0("Steps_", rasterized$steps, "_Sampling_", rasterized$sampling)
# Prepare nice layernames
names <- paste0("Steps_", rasterized$steps, "_Sampling_", rasterized$area)
# Put heatmaps into a stack
heatmaps <- do.call(c, heatmaps)
names(heatmaps) <- names
# Store the final stack
heatmaps <- writeRaster(heatmaps
, "03_Data/03_Results/99_RasterizedSimulations.tif"
, overwrite = T
)
# Put them into the tibble
rasterized$heatmap <- vector(mode = "list", length = nrow(rasterized))
for (i in 1:nrow(rasterized)){
rasterized$heatmap[[i]] <- heatmaps[[i]]
}
rasterized$heatmap[[1]]
plot(rasterized$heatmap[[1]])
plot(rasterized$heatmap[[2]])
plot(rasterized$heatmap[[3]])
plot(rasterized$heatmap[[5]])
plot(rasterized$heatmap[[3]])
plot(rasterized$heatmap[[1]])
plot(rasterized$heatmap[[4]])
plot(rasterized$heatmap[[6]])
plot(rasterized$heatmap[[7]])
plot(rasterized$heatmap[[12]])
